# !/usr/bin/python
# coding = utf-8
# ç”¨äºè·å–æœ€ä¼˜çš„Kå€¼


import gensim
import jieba
from gensim.models.doc2vec import Doc2Vec
from matplotlib import pyplot as plt
from matplotlib import font_manager
from sklearn import cluster


my_font = font_manager.FontProperties(fname="/usr/share/fonts/truetype/arphic/uming.ttc")
TaggededDocument = gensim.models.doc2vec.TaggedDocument
def GetTrainSet():
    fnames = []
    for i in range(1, 2550):
        fname = '/home/wangzeju/æ¡Œé¢/lunwen/safevent/' + str(i) + '.txt'
        fnames.append(fname)
    # ç”¨æ¥å­˜æ”¾è¯­æ–™
    train_data = []
    for name in fnames:
        with open(name) as f:
            data = f.read().replace('\n', '')
            f.close()
            train_data.append(data)
    #   print('append ok!')
    return train_data


    # åˆ†è¯
def CutDoc(train_data):
    stop_path = '/home/wangzeju/æ¡Œé¢/lunwen/stop.txt'
    with open(stop_path) as f:
        stop_list = f.readlines()
    result = []
    for each in train_data:
        each_cut = jieba.cut(each)
        each_split = ' '.join(each_cut).split()
        each_result = [word for word in each_split if word not in stop_list]
        result.append(' '.join(each_result))
    # è¾“å‡ºä¸ºä¸€ç»´æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ç¯‡æ–‡æ¡£
    # print(result)
    return result


def InitData(result):
    # æ¯ä¸€ç¯‡æ–‡æ¡£éœ€è¦ä¸€ä¸ªå¯¹åº”çš„ç¼–å·
    index = 0
    # ç”¨æ¥å­˜æ”¾è¯­æ–™
    x_train = []
    # ç”±ç¼–å·æ˜ å°„æ–‡æ¡£IDçš„å­—å…¸
    doc_dict = {}
    for words in result:
        # è¯­æ–™é¢„å¤„ç†
        x_train.append(TaggededDocument(words, tags=[index]))
        doc_dict[index] = str(index + 1) + '.txt'
        #        print('append ok!')
        index += 1
    # print(doc_dict)
    return x_train, doc_dict


# ç¬¬äºŒæ­¥ï¼Œåˆå§‹åŒ–è®­ç»ƒæ¨¡å‹çš„å‚æ•°ï¼Œå†ä¿å­˜è®­ç»ƒç»“æœä»¥é‡Šæ”¾å†…å­˜
def Train(x_train, size=100):
    model_dbom = gensim.models.Doc2Vec(x_train, dm=1, alpha=0.1, min_count=0, window=5, vector_size=size,
                                       min_alpha=0.025)
    # æ¨¡å‹çš„åˆå§‹åŒ–ï¼Œè®¾ç½®å‚æ•°
    # æä¾›x_trainå¯åˆå§‹åŒ–,min_coutå¿½ç•¥æ€»é¢‘ç‡ä½äºè¿™ä¸ªçš„æ‰€æœ‰å•è¯,windowé¢„æµ‹çš„è¯ä¸ä¸Šä¸‹æ–‡è¯ä¹‹é—´æœ€å¤§çš„è·ç¦», ç”¨äºé¢„æµ‹sizeç‰¹å¾å‘é‡çš„ç»´æ•°
    model_dbom.train(x_train, total_examples=model_dbom.corpus_count, epochs=10)
    # corpus_countæ˜¯æ–‡ä»¶ä¸ªæ•°  epochs è®­ç»ƒæ¬¡æ•°
    model_dbom.save('/home/wangzeju/æ¡Œé¢/lunwen/doc2vec2.model')
    return model_dbom


    # ç¬¬ä¸‰æ­¥ï¼Œç”Ÿæˆæ–‡æ¡£çš„å‘é‡è¡¨è¾¾
def Test(result):
    model_dbom = Doc2Vec.load("/home/wangzeju/æ¡Œé¢/lunwen/doc2vec2.model")
    doc_id = 1
    doc_vectors = []
    # åŠ è½½è®­ç»ƒçš„æ¨¡å‹
    for text in result:
        #  print(text)
        vector = model_dbom.infer_vector([text])
        # å°†è¯¥æ•°ç»„å¯¼å…¥åˆ°èšç±»ä¸­ï¼Œä»¥æ— ç›‘ç£çš„æ–¹å¼èšç±»ï¼Œå¯ä»¥å¾—åˆ°ç±»ç°‡ï¼Œä½†æ˜¯æ¯ä¸ªç±»ç°‡ä¸­æ–‡æ¡£çš„idå¦‚ä½•ç¡®å®šæœ‰å¾…è§£å†³ğŸ˜‚ï¸
        doc_vectors.append(vector)
        doc_id += 1
    # è¿”å›äºŒç»´æ•°ç»„
    return doc_vectors


def Kmeans(doc_vectors,k):
    data = doc_vectors
    clst = cluster.KMeans(n_clusters=k,init='k-means++',n_init=10,max_iter=100,tol=1e-4,random_state=0)
    clst.fit(data)
    distortion = clst.inertia_
    return distortion


def plot(sses):
    K = [k for k in range(1,201)]
    plt.figure()
    plt.plot(K,sses)
    plt.xlabel('ç°‡æ•°é‡',fontproperties=my_font)
    plt.ylabel('SSE')
    plt.show()


if __name__ == '__main__':
    # è·å–é¢„å¤„ç†çš„è¯­æ–™
    train_data = GetTrainSet()
    # ä¸­æ–‡åˆ†è¯ï¼Œåˆ†è¯åçš„è¯­æ–™åº“ï¼Œè¿”å›äºŒç»´æ•°ç»„
    result = CutDoc(train_data)
    # åˆ©ç”¨åº“åˆå§‹åŒ–æ•°æ®ï¼Œè¿”å›ï¼ˆæ ‡ç­¾ï¼Œæ–‡æ¡£å‘é‡ï¼‰æ„æˆçš„äºŒç»´æ•°ç»„ï¼Œæ–‡æ¡£è¯å…¸
    x_train, doc_dict = InitData(result)
    # è®­ç»ƒæ¨¡å‹
    model = Train(x_train)
    # æµ‹è¯•ï¼Œï¼ˆç”Ÿæˆæ–‡æ¡£å‘é‡)
    doc_vectors = Test(result)
    # print(doc_vectors)

    sses = []
    for k in range(1,201):
        sse = Kmeans(doc_vectors,k)
        sses.append(sse)
    plot(sses)

